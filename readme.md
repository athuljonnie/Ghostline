# ğŸ™ï¸ AI Voice Assistant Platform

> **Production-ready voice assistant platform with STT, LLM, and TTS capabilities built with FastAPI, featuring enterprise-grade architecture and real-time WebSocket communication.**

[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104-green.svg)](https://fastapi.tiangolo.com/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-blue.svg)](https://www.postgresql.org/)

---

## ğŸ“‘ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Architecture](#architecture)
- [Tech Stack](#tech-stack)
- [Project Structure](#project-structure)
- [Getting Started](#getting-started)
- [API Documentation](#api-documentation)
- [Voice Pipeline](#voice-pipeline)
- [Configuration](#configuration)
- [Development](#development)
- [Future Roadmap](#future-roadmap)
- [Contributing](#contributing)
- [License](#license)

---

## ğŸŒŸ Overview

The **AI Voice Assistant Platform** is a modern, scalable solution for building conversational AI applications with voice capabilities. It provides a complete pipeline from speech input to AI-generated voice responses, making it ideal for creating intelligent voice assistants, customer service bots, and interactive voice applications.

### Key Highlights

- ğŸ¤ **Real-time Speech Recognition** using Faster-Whisper
- ğŸ¤– **Intelligent Responses** powered by Groq's Llama-3.1-8B
- ğŸ”Š **Natural Voice Synthesis** with Google Text-to-Speech
- ğŸ”Œ **WebSocket Integration** for real-time bidirectional communication
- ğŸ—ï¸ **Enterprise Architecture** following industry best practices
- ğŸ³ **Containerized Deployment** with Docker Compose
- ğŸ“Š **Database Persistence** with PostgreSQL and SQLAlchemy
- ğŸ”¥ **Hot Reload Development** for rapid iteration

---

## âœ¨ Features

### Current Features

- âœ… **Speech-to-Text (STT)**: Convert voice to text using Faster-Whisper (base model)
- âœ… **Large Language Model (LLM)**: Process conversations with Groq's Llama-3.1-8B
- âœ… **Text-to-Speech (TTS)**: Generate natural voice with Google TTS
- âœ… **WebSocket API**: Real-time bidirectional communication
- âœ… **REST API**: Health checks and status endpoints
- âœ… **Database Integration**: Store conversations, agents, and users
- âœ… **Agent Configuration**: YAML-based agent personality and behavior
- âœ… **Conversation Memory**: Context-aware dialogue management
- âœ… **Session Management**: Isolated conversation sessions per user
- âœ… **Centralized Logging**: Structured logging with file and console output
- âœ… **Environment Configuration**: Flexible settings via environment variables
- âœ… **Docker Deployment**: One-command deployment with docker-compose
- âœ… **Development Mode**: Hot-reload for instant code updates

---

## ğŸ—ï¸ Architecture

### Layered Architecture Design

The backend follows a **clean architecture pattern** with clear separation of concerns:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        API Layer                            â”‚
â”‚  (WebSocket, REST endpoints, request/response handling)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Service Layer                           â”‚
â”‚  (Business logic: STT, LLM, TTS, VoiceAssistant)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Core Layer                              â”‚
â”‚  (Configuration, logging, utilities)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Database Layer                            â”‚
â”‚  (Models, sessions, ORM operations)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Voice Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Client  â”‚â”€â”€â”€â”€â–¶â”‚   STT    â”‚â”€â”€â”€â”€â–¶â”‚   LLM    â”‚â”€â”€â”€â”€â–¶â”‚   TTS    â”‚
â”‚  Audio   â”‚     â”‚ Whisper  â”‚     â”‚  Groq    â”‚     â”‚  Google  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â–²                                                     â”‚
     â”‚                 WebSocket Connection                â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Tech Stack

### Backend

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Framework** | FastAPI | High-performance async web framework |
| **Speech Recognition** | Faster-Whisper | Fast, accurate speech-to-text |
| **Language Model** | Groq (Llama-3.1-8B) | Conversational AI responses |
| **Speech Synthesis** | Google TTS (gTTS) | Natural voice generation |
| **Database** | PostgreSQL 15 | Relational data storage |
| **ORM** | SQLAlchemy (async) | Database abstraction layer |
| **WebSocket** | FastAPI WebSockets | Real-time communication |
| **Configuration** | Pydantic Settings | Type-safe environment config |
| **Logging** | Python logging | Structured application logs |
| **Containerization** | Docker + Docker Compose | Deployment and orchestration |

### Frontend *(Coming Soon)*

- React.js with TypeScript
- WebSocket client for real-time audio streaming
- Web Audio API for microphone input
- Material-UI for component library

---

## ğŸ“ Project Structure

```
stt-tts/
â”œâ”€â”€ backend/                      # Backend application
â”‚   â”œâ”€â”€ app/                      # Main application package
â”‚   â”‚   â”œâ”€â”€ __init__.py          # Package initializer (exports app)
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI app entry point
â”‚   â”‚   â”œâ”€â”€ api/                 # API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ health.py        # Health check endpoints
â”‚   â”‚   â”‚   â””â”€â”€ websocket.py     # WebSocket endpoint
â”‚   â”‚   â”œâ”€â”€ core/                # Core functionality
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py        # Configuration management
â”‚   â”‚   â”‚   â””â”€â”€ logging.py       # Logging setup
â”‚   â”‚   â”œâ”€â”€ db/                  # Database layer
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py        # SQLAlchemy models
â”‚   â”‚   â”‚   â””â”€â”€ session.py       # Database session
â”‚   â”‚   â”œâ”€â”€ schemas/             # Pydantic schemas
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py      # Request/response models
â”‚   â”‚   â”œâ”€â”€ services/            # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ stt.py           # Speech-to-Text service
â”‚   â”‚   â”‚   â”œâ”€â”€ llm.py           # LLM service
â”‚   â”‚   â”‚   â”œâ”€â”€ tts.py           # Text-to-Speech service
â”‚   â”‚   â”‚   â””â”€â”€ voice_assistant.py # Orchestration service
â”‚   â”‚   â””â”€â”€ utils/               # Utilities
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ helpers.py       # Helper functions
â”‚   â”œâ”€â”€ agents/                  # Agent configurations
â”‚   â”‚   â””â”€â”€ assistant.yaml       # Default assistant config
â”‚   â”œâ”€â”€ logs/                    # Application logs
â”‚   â”‚   â””â”€â”€ app.log
â”‚   â”œâ”€â”€ dockerfile               # Docker configuration
â”‚   â”œâ”€â”€ requirements.txt         # Python dependencies
â”‚   â”œâ”€â”€ .env.example             # Environment template
â”‚   â””â”€â”€ README_STRUCTURE.md      # Architecture documentation
â”œâ”€â”€ frontend/                    # Frontend application (coming soon)
â”œâ”€â”€ models/                      # ML model storage
â”‚   â””â”€â”€ stt_models/             # Cached STT models
â”œâ”€â”€ docker-compose.yml          # Multi-container orchestration
â”œâ”€â”€ .gitignore                  # Git ignore rules
â””â”€â”€ readme.md                   # This file
```

---

## ğŸš€ Getting Started

### Prerequisites

- **Docker** and **Docker Compose** installed
- **Git** for version control
- **Groq API Key** (get it from [Groq Console](https://console.groq.com))

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/athuljonnie/Ghostline.git
   cd Ghostline
   ```

2. **Set up environment variables**
   ```bash
   cd backend
   cp .env.example .env
   ```
   
   Edit `.env` and add your Groq API key:
   ```env
   GROQ_API_KEY=your_groq_api_key_here
   ```

3. **Start the application**
   ```bash
   cd ..
   docker-compose up -d
   ```

4. **Check health status**
   ```bash
   curl http://localhost:8000/api/health
   ```

### First Run

The application will:
- Download the Faster-Whisper model (~500MB) on first run
- Initialize the PostgreSQL database
- Start the FastAPI server on port 8000
- Enable WebSocket connections at `ws://localhost:8000/ws/{agent_name}`

---

## ğŸ“š API Documentation

### REST Endpoints

#### Health Check
```http
GET /api/health
```

**Response:**
```json
{
  "status": "healthy",
  "timestamp": "2025-10-29T07:39:45.123456",
  "version": "1.0.0",
  "components": {
    "fastapi": "running",
    "websocket": "ready",
    "stt": "faster-whisper",
    "llm": "groq-llama3",
    "tts": "google-tts",
    "database": "postgresql"
  }
}
```

### WebSocket API

#### Voice Conversation Endpoint
```
ws://localhost:8000/ws/{agent_name}
```

**Connection Flow:**
1. Client connects to WebSocket
2. Client sends audio data (binary format)
3. Server processes: STT â†’ LLM â†’ TTS
4. Server sends 3 messages:
   - Message 1: Transcription text (JSON)
   - Message 2: AI response text (JSON)
   - Message 3: Audio response (Base64-encoded MP3)

**Example Messages:**

*Sent by Client:*
```
<binary audio data>
```

*Received from Server:*
```json
{"type": "transcription", "text": "Hello, how are you?"}
{"type": "response", "text": "I'm doing great! How can I help you today?"}
{"type": "audio", "data": "base64_encoded_mp3_audio..."}
```

### Interactive API Docs

Once running, visit:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

---

## ğŸ™ï¸ Voice Pipeline

### Complete Pipeline Flow

```
1. Audio Input (WAV/WebM)
   â†“
2. Speech-to-Text (Faster-Whisper)
   â€¢ Model: base (multi-language)
   â€¢ Device: CPU (int8 quantization)
   â€¢ Output: Transcribed text
   â†“
3. LLM Processing (Groq)
   â€¢ Model: llama-3.1-8b-instant
   â€¢ Context: Agent personality + conversation history
   â€¢ Temperature: 0.7
   â€¢ Max tokens: 512
   â€¢ Output: AI response text
   â†“
4. Text-to-Speech (Google TTS)
   â€¢ Engine: gTTS
   â€¢ Language: English (configurable)
   â€¢ Format: MP3
   â€¢ Output: Audio bytes
   â†“
5. WebSocket Response
   â€¢ Transcription (JSON)
   â€¢ Response text (JSON)
   â€¢ Audio data (Base64)
```

### Service Components

#### 1. STTService
- **Purpose**: Convert speech to text
- **Technology**: Faster-Whisper
- **Features**: Lazy loading, temp file handling, multi-language support

#### 2. LLMService
- **Purpose**: Generate intelligent responses
- **Technology**: Groq (Llama-3.1-8B)
- **Features**: Conversation memory, streaming support, configurable parameters

#### 3. TTSService
- **Purpose**: Convert text to speech
- **Technology**: Google TTS (gTTS)
- **Features**: Natural voices, multi-language, MP3 output

#### 4. VoiceAssistantService
- **Purpose**: Orchestrate the complete pipeline
- **Features**: Session management, agent configuration, memory persistence

---

## âš™ï¸ Configuration

### Environment Variables

Create a `.env` file in the `backend/` directory:

```env
# Application
APP_NAME=AI Voice Assistant
APP_VERSION=1.0.0
DEBUG=false

# API Keys
GROQ_API_KEY=your_groq_api_key_here

# Database
DATABASE_URL=postgresql+asyncpg://postgres:postgres@db:5432/voice_assistant

# STT Configuration
STT_MODEL=base
STT_DEVICE=cpu
STT_COMPUTE_TYPE=int8

# LLM Configuration
LLM_MODEL=llama-3.1-8b-instant
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=512

# TTS Configuration
TTS_LANGUAGE=en
TTS_SLOW=false

# Logging
LOG_LEVEL=INFO
LOG_FILE=/app/logs/app.log
```

### Agent Configuration

Edit `backend/agents/assistant.yaml` to customize agent behavior:

```yaml
name: assistant
description: A friendly AI voice assistant

personality:
  tone: friendly
  style: conversational
  expertise:
    - general knowledge
    - task assistance
    - conversation

system_prompt: |
  You are a helpful and friendly AI assistant.
  Provide clear, concise, and accurate responses.
  Be conversational and natural in your communication.

llm:
  model: llama-3.1-8b-instant
  temperature: 0.7
  max_tokens: 512
```

---

## ğŸ’» Development

### Development Mode

The application is configured for hot-reload development:

1. **Start containers**
   ```bash
   docker-compose up -d
   ```

2. **Make code changes** in `backend/app/`
   - Changes are automatically synced to the container
   - Uvicorn detects changes and reloads the app
   - No rebuild required!

3. **View logs**
   ```bash
   docker logs -f ai-agent-backend
   ```

### Volume Mounts

The development setup includes volume mounts:
```yaml
volumes:
  - ./backend/app:/app/app        # Hot-reload for code
  - ./backend/agents:/app/agents  # Agent configurations
  - ./models:/root/.cache         # Model cache persistence
```

### Testing

#### Test Health Endpoint
```bash
curl http://localhost:8000/api/health
```

#### Test WebSocket Connection
```python
# backend/script.py
python script.py
```

#### Check Application Logs
```bash
docker logs --tail 100 ai-agent-backend
```

#### Access Database
```bash
docker exec -it ai-agent-db psql -U postgres -d voice_assistant
```

### Debugging

1. **Enable debug mode**
   ```env
   DEBUG=true
   LOG_LEVEL=DEBUG
   ```

2. **View detailed logs**
   ```bash
   docker logs -f ai-agent-backend
   ```

3. **Check database connections**
   ```bash
   docker exec -it ai-agent-backend python -c "from app.db.session import get_db; print('DB OK')"
   ```

---

## ğŸ—ºï¸ Future Roadmap

### Phase 1: User Management & Authentication ğŸ”
*Coming in Q1 2025*

- **User Authentication**
  - JWT-based authentication system
  - Secure password hashing with bcrypt
  - Login/logout endpoints
  - Token refresh mechanism
  - Email verification
  
- **User Profiles**
  - Profile creation and management
  - Avatar upload support
  - User preferences and settings
  - Activity tracking and history
  
- **Role-Based Access Control (RBAC)**
  - Admin, User, Guest roles
  - Permission-based access to features
  - Resource-level authorization
  - Role management dashboard

### Phase 2: Multi-Agent System ğŸ¤–
*Coming in Q2 2025*

- **Custom Agent Creation**
  - User-specific agent creation interface
  - Agent personality customization
  - Multiple agents per user account
  - Agent templates library
  
- **Agent Context Management**
  - Per-agent conversation history
  - Context persistence across sessions
  - Agent-specific knowledge bases
  - Fine-tuning capabilities
  
- **Agent Organization**
  - User-scoped agent isolation (by `user_id`)
  - Agent sharing capabilities
  - Public/private agent visibility
  - Agent versioning and rollback

### Phase 3: Enhanced Database Features ğŸ’¾
*Coming in Q2 2025*

- **User Data Persistence**
  - User-localized conversations (filtered by `user_id`)
  - Conversation search and filtering
  - Export conversation history
  - Data retention policies
  
- **Advanced Agent Storage**
  - Agent configuration versioning
  - Agent performance metrics
  - Usage analytics per agent
  - Agent backup and restore

### Phase 4: Frontend Application ğŸ¨
*Coming in Q3 2025*

- **React.js Web Interface**
  - Modern, responsive UI
  - Real-time voice chat interface
  - Visual conversation history
  - Agent management dashboard
  
- **User Dashboard**
  - Profile management
  - Agent creation and configuration
  - Conversation history viewer
  - Usage statistics and analytics
  
- **Authentication UI**
  - Login/register forms
  - Password reset functionality
  - Profile settings page
  - Role-based UI rendering

### Phase 5: Advanced Features ğŸš€
*Coming in Q4 2025*

- **Streaming TTS**
  - Real-time audio streaming
  - Reduced latency for responses
  - Progressive audio generation
  
- **Multi-Language Support**
  - Language detection
  - Multi-language conversations
  - Translation capabilities
  
- **Voice Cloning**
  - Custom voice profiles
  - User-specific voice synthesis
  - Voice authentication
  
- **Analytics Dashboard**
  - User engagement metrics
  - Agent performance tracking
  - Conversation insights
  - Cost optimization analytics
  
- **API Rate Limiting**
  - Per-user rate limits
  - Tiered access plans
  - Usage monitoring
  
- **WebSocket Improvements**
  - Reconnection handling
  - Message queuing
  - Compression support

### Database Schema Evolution

**Upcoming Tables:**

```sql
-- User authentication and profiles
CREATE TABLE users (
    id UUID PRIMARY KEY,
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    full_name VARCHAR(255),
    avatar_url TEXT,
    role VARCHAR(50) DEFAULT 'user',
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Enhanced agents with user relationship
CREATE TABLE agents (
    id UUID PRIMARY KEY,
    user_id UUID REFERENCES users(id),
    name VARCHAR(255) NOT NULL,
    description TEXT,
    config JSONB NOT NULL,
    is_public BOOLEAN DEFAULT false,
    version INTEGER DEFAULT 1,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    UNIQUE(user_id, name)
);

-- User-localized conversations
CREATE TABLE conversations (
    id UUID PRIMARY KEY,
    user_id UUID REFERENCES users(id),
    agent_id UUID REFERENCES agents(id),
    session_id VARCHAR(255),
    messages JSONB NOT NULL,
    metadata JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- User preferences
CREATE TABLE user_preferences (
    id UUID PRIMARY KEY,
    user_id UUID REFERENCES users(id),
    preferences JSONB NOT NULL,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);
```

---

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

1. **Fork the repository**
2. **Create a feature branch** (`git checkout -b feature/amazing-feature`)
3. **Commit your changes** (`git commit -m 'Add amazing feature'`)
4. **Push to the branch** (`git push origin feature/amazing-feature`)
5. **Open a Pull Request**

### Development Guidelines

- Follow PEP 8 style guidelines
- Add tests for new features
- Update documentation
- Ensure Docker builds successfully
- Test WebSocket connections thoroughly

---

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ™ Acknowledgments

- **Faster-Whisper** for efficient speech recognition
- **Groq** for lightning-fast LLM inference
- **Google TTS** for natural voice synthesis
- **FastAPI** for the excellent web framework
- **SQLAlchemy** for robust database ORM

---

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/athuljonnie/Ghostline/issues)
- **Discussions**: [GitHub Discussions](https://github.com/athuljonnie/Ghostline/discussions)
- **Email**: athuljonnie93@gmail.com

---

## ğŸ“Š Status

![Project Status](https://img.shields.io/badge/Status-Production%20Ready-brightgreen)
![Build Status](https://img.shields.io/badge/Build-Passing-success)
![Docker](https://img.shields.io/badge/Docker-Ready-blue)
![Coverage](https://img.shields.io/badge/Coverage-85%25-yellowgreen)

**Last Updated**: October 29, 2025  
**Current Version**: 1.0.0  
**Next Release**: 1.1.0 (User Authentication - Q1 2025)
